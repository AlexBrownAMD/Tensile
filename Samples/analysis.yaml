#What the resulting analysis file should look like after Phase 2

# Parameters which stay in original config.yaml
# Name
# each problem type needs to choose DoWhile vs For

ProblemType
  OperationType: GEMM
  DataType: s
  TransposeA: False
  TransposeB: True
  UseBeta: False
  Solutions:
    - { WorkGroup0:  8, WorkGroup1: 16, LoopUnroll: 8 } # S0
    - { WorkGroup0: 16, WorkGroup1: 16, LoopUnroll: 8 } # S1
    - { WorkGroup0:  8, WorkGroup1:  8, LoopUnroll: 8 } # S2
  DimensionOrder: [ 0, 1, 2 ]
  SolutionSelection:
    #   dim0   dim1  dim2                                   dim1  dim2
    # [ min, [ min, [min, sid], [min, sid], [min, sid] ], [ min, [min, sid], [min, sid] ] ]
    # [ min, [ min, [min, sid], [min, sid], [min, sid] ], [ min, [min, sid], [min, sid] ] ]
    - 0 # 0->128
      - 0 # 0->128
        - [    0, 0] # 324 GFlop/s
        - [  128, 1]
        - [ 1024, 2]
      - 128
        - [    0, 0]
        - [  128, 1]
        - [ 1024, 2]
      - 1024
        - [    0, 0]
        - [  128, 1]
        - [ 1024, 2]
    - 128
      - 0
        - [    0, 0]
        - [  128, 1]
        - [ 1024, 2]
      - 128
        - [    0, 0]
        - [  128, 1]
        - [ 1024, 2]
      - 1024
        - [    0, 0]
        - [  128, 1]
        - [ 1024, 2]
    - 1024
      - 0
        - [    0, 0]
        - [  128, 1]
        - [ 1024, 2]
      - 128
        - [    0, 0]
        - [  128, 1]
        - [ 1024, 2]
      - 1024
        - [    0, 0]
        - [  128, 1]
        - [ 1024, 2]
# if dU > 0
#foeach size in unroll dimension:
# check what d0=d1 kernels is best
# skinny 0: (large d0, small d1)
#   for largest several d0
#   starting at d1 =0 -> large
#     until fastest kernel at skinny == fastest kernel square: d1_nonSkinnyThreshold = 352
#     everytime fastest kernel changes, create a split size for d1_splits={160, 192, 224, 352}
#   foreach d1_split
#     for d0 = large -> 0 unril fastest == nonSkinnyFastest
#       everytime fastest kernel changes, create a rule
#   
# skinny 1:
#
#
#   skinny 0
#   if d0 < 192 skinny
#     if d1 > 4000: 3
#     if d1 >  200: 2
#   if d0 < 384
#     if d1 > 6000: 3
#     if d1 >  800: 2
#
#   skinny 1
#   if d1 < 192 skinny
#     if d0 > 4000: 3
#     if d0 >  200: 2
#   if d1 < 384
#     if d0 > 6000: 3
#     if d0 >  800: 2
#
#   not skinny
#   if d0*d1 > 4000: 8
#   if d0*d1 > 2000: 4
#   if d0*d1 > 1000: 3
#   if d0*d1 > 1000: 3
#
# how to generalize to multiple dimensions, such as batched
# all other dims just increase wg count
#
# before rule creation, we can scan across all dU benchmarks and analyse which
# are approximately the same
# layers uA and uB can be merged if for every size dU*d0*d1 the winner wA
# for layer uA gets performance pA, and solution wA for layer uB get performance
# within threshold of winner wB for layer uB, i.e. merging the two layers
# will never hurt performance more than threshold
#
# how to expand this logic to account for many data points where most are
# within threshold but some are not
#
#
#
#
#
#

# methods for clustering
# 1) start with fully expanded logic and iterativly collapse if performance stays above threshold
# 2) hardcode number of splits in each dimension
#
