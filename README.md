# Cobalt

A core math library back end to domain-specific libraries for multi-dimensional convolutions, tensor contractions, matrix-matrix multiplication, higher-order inner-products and anything else that multiplies two objects together on a gpu using any desired language (OpenCL, HSA, C++ lambda functions).

## Motivation:
The following three multi-dimensional mathematical operations

1) Convolutions (1D, 2D, 3D)
2) Inner-Products (including GEMM)
3) Tensor contractions

not only share the same overall behavior of

1) multiply groups of elements of A with corresponding groups of elements of B
2) sum the group
3) write group's sum to particular location in C

but they all share the same core/inner-most-loop for achieving peak floating-point throughput on GPUs:

1)	load elements of A from global -> local memory
2)	load elements of B from global -> local memory
3)	load m elements of A into registers
4)	load n elements of B into registers
5)	do m\*n multiply-accumulate operations in registers

Cobalt will be a single library back-end, similar to the successful AutoGemm, a "library behind the libraries", to flexibly generate gpu kernels (append domain-specific prefix and suffix to common inner-most-loop) and some necessary host-code to use in domain specific libraries.

## Development Timeline:

CobaltGenBenchmark
  Reader
    getProblemsFromXML - DONE
  Engine
    genSolutionSelectionLogic
      selectSolutionSpecific - 1 week
    getSolutionsToProblem - DONE
    getKernelsFromSolution - DONE
  Writer
    writeKernels
      getBody(opencl) - DONE
    writeSolutionClasses
      header file - DONE
      source file - DONE
    writeBenchmarkHeaders
      list of problems and every matching solution - 1 week
    writeSolutionSelectionLogic - 1 week

CobaltGenBackend
  Reader
    getProblemSolutionMapFromXML - 2 weeks
  Engine
    simplifyProblemSolutionMap - 2 weeks
  Writer
    writeKernels (duplicate)
    writeSolutionClasses (duplicate)
    writeKernelSelectionLogic

CobaltLib
  write validation - 2 week
Apps
  exhaustive gemms - 1 week
  benchmarking architecture - 2 weeks

After writing this
validate gemm solutions - 2 weeks
validate solution selection logic - 1 week
validate Cobalt architecture (multiple objects devices) - 2 weeks

= 6 months for GEMM to work on OpenCL 1.2
+ advanced tensors = 2 weeks
+ other language = 4 weeks (mostly Solution.cpp "enqueueing")

For what different devices do we need to pre-compile

What can easily be allowed to differ between the kernels of a solution
  workGroup
  microTile
  kernel signature
NOT
  index assignments?

## CMaking Cobalt

### Option 1
from aBLAS:
- aBLAS gets Cobalt repo via external project
- aBLAS has its own backend option which also gets passed to Cobalt config
- aBLAS has its own aBLASProbSolvMap.xml which gets passed to Cobalt config
- aBLAS tells Cobalt to build itself
  - CobaltGenBackend.py produces files.cpp and file.cmake
  - Cobalt CMake has to reload file.cmake - configure\_file
  - Cobalt build builds Cobalt.lib
- aBLAS builds itself and links in Cobalt.lib

from Cobalt:
- build options: backend, directory of .xml files, output dir is own BINARY\_DIR

need 2 build modes: Isolated and AsExternalProject
Isolated - builds clients, does benchmarking
AsExternalProject - skips to the end

### Option 2
from aBLAS:

generated CMakeLists.txt
https://cmake.org/pipermail/cmake/2011-November/047333.html
- 


if Backend.cmake doesn't exist, create one for LOG\_ONLY\_MODE

Backend.cmake
regenerating Backend.cmake will spawn rebuilding CobaltLib

Target: CobaltLib w/ backend; depends on Backend.cmake

EXTERNAL\_PROJECT Entry Point 1,2

Target: AppALL.exe depends on Cobalt.lib Backend.cmake (

Target: AppProblems.xml generated by custom\_command AppALL.exe

DONE Target: SolutionCandidates.cpp and Benchmark.cmake generated by custom\_command CobaltGenBenchmark.py with input AppProblems.xml

DONE Target: Benchmark.exe depends on SolutionCandidates.cpp and Benchmark.cmake

DONE Target: ProbSolMap.xml generated from custom\_command Benchmark.exe which depends on compiling Benchmark.exe

EXTERNAL\_PROJECT Entry Point 3

DONE Target: GetSolution.cpp generated from custom\_command CobaltGenBackend.py with input ProbSolMap.xml

DONE Target: static CobaltLib generated files (GetSolution.cpp)

Entry Point 1
  Cobalt:AppALL wants the full build process
Entry Point 2
  aBLAS:AppALL:aBLASLib wants CobaltLibLogger
  sends output path for AppProbs.xml
  gets CobaltLib.lib (log)
Entry Point 3
  aBLAS:Lib wants CobaltLibFull Project without benchmarking
  sends aBLAS\_ProbSolMap.xml
  gets CobaltLib.lib (full)


